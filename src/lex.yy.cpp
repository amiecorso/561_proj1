// lex.yy.cpp generated by reflex 1.4.3 from py_strip.lxx

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  OPTIONS USED                                                              //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#define REFLEX_OPTION_lex                 yylex
#define REFLEX_OPTION_lexer               Lexer
#define REFLEX_OPTION_namespace           yy
#define REFLEX_OPTION_nodefault           true
#define REFLEX_OPTION_noyywrap            true
#define REFLEX_OPTION_outfile             "lex.yy.cpp"

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  SECTION 1: %top{ user code %}                                             //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#line 1 "py_strip.lxx"

/* Python source normalization for plagiarism checker
 * (example only)
 * 2019 Fall version with RE/flex,
 *
 */

 #include <iostream>


////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  REGEX MATCHER                                                             //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#include <reflex/matcher.h>

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  ABSTRACT LEXER CLASS                                                      //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#include <reflex/abslexer.h>

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  LEXER CLASS                                                               //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

namespace yy {

class Lexer : public reflex::AbstractLexer<reflex::Matcher> {
 public:
  typedef reflex::AbstractLexer<reflex::Matcher> AbstractBaseLexer;
  Lexer(
      const reflex::Input& input = reflex::Input(),
      std::ostream&        os    = std::cout)
    :
      AbstractBaseLexer(input, os)
  {
  }
  static const int INITIAL = 0;
  static const int q = 1;
  static const int Q = 2;
  static const int qqq = 3;
  static const int QQQ = 4;
  virtual int yylex();
  int yylex(
      const reflex::Input& input,
      std::ostream        *os = NULL)
  {
    in(input);
    if (os)
      out(*os);
    return yylex();
  }
};

} // namespace yy

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  SECTION 1: %{ user code %}                                                //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#line 14 "py_strip.lxx"
/* Lexical states to avoid big hairy patterns ---
   * %x is for an 'exclusive' state.
   * See https://www.genivia.com/doc/reflex/html/index.html#reflex-states
   * Python has 's', "s",  """s""", '''s'''.
   * We'll abbreviate quoted modes with q for ', Q for "
   */

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  SECTION 2: rules                                                          //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

int yy::Lexer::yylex()
{
  static const char *REGEX_INITIAL = "(?m)(#.*)|(')|(''')|(\")|(\"\"\")|(False|await|else|import|pass)|(None|break|except|in|raise)|(True|class|finally|is|return)|(and|continue|for|lambda|try)|(as|def|from|nonlocal|while)|(assert|del|global|not|with)|(async|elif|if|or|yield)|(abs|delattr|hash|memoryview|set|all)|(dict|help|min|setattr|any|dir|hex)|(next|slice|ascii|divmod|id|object)|(sorted|bin|enumerate|input|oct)|(staticmethod|bool|eval|int|open|str)|(breakpoint|exec|isinstance|ord|sum)|(bytearray|filter|issubclass|pow)|(super|bytes|float|iter|print|tuple)|(callable|format|len|property|type)|(chr|frozenset|list|range|vars)|(classmethod|getattr|locals|repr)|(zip|compile|globals|map|reversed)|(__import__|complex|hasattr|max|round)|(__new__|__init__|__del__)|(__cmp__|__eq__|__ne__)|(__lt__|__gt__|__le__|__ge__)|(__pos__|__neg__|__abs__)|(__add__|__sub__|__mul__|__div__)|(__str__|__repr__|__format__)|(__iter__|__len__|__contains__)|([a-z][0-9A-Z_a-z]*)|([A-Z][0-9A-Z_a-z]*)|([_][0-9A-Z_a-z]*)|((?:[\\x09\\x0a\\x0d\\x20]|#.*)*\\n)|(.)";
  static const reflex::Pattern PATTERN_INITIAL(REGEX_INITIAL);
  static const char *REGEX_q = "(?m)(')|([\\x5c].)|(.)";
  static const reflex::Pattern PATTERN_q(REGEX_q);
  static const char *REGEX_Q = "(?m)(\")|([\\x5c].)|(.)";
  static const reflex::Pattern PATTERN_Q(REGEX_Q);
  static const char *REGEX_qqq = "(?m)(''')|([\\x5c].)|(\\n)|(.)";
  static const reflex::Pattern PATTERN_qqq(REGEX_qqq);
  static const char *REGEX_QQQ = "(?m)(\"\"\")|([\\x5c].)|(\\n)|(.)";
  static const reflex::Pattern PATTERN_QQQ(REGEX_QQQ);
  if (!has_matcher())
  {
    matcher(new Matcher(PATTERN_INITIAL, stdinit(), this));
  }
  switch (start())
  {
    case INITIAL:
#line 28 "py_strip.lxx"
/* End-of-line comments start with #.  Chop them. */
    break;
  }
  while (true)
  {
    switch (start())
    {
      case INITIAL:
        matcher().pattern(PATTERN_INITIAL);
        switch (matcher().scan())
        {
          case 0:
            if (matcher().at_end())
            {
#line 119 "py_strip.lxx"
{ return 0; }

            }
            else
            {
              lexer_error("scanner jammed");
              return int();
            }
            break;
          case 1: // rule at line 28: #.*
#line 28 "py_strip.lxx"
{ ; }

  /* Strings.  We'll preserve them, although maybe we should chop them?  */
            break;
          case 2: // rule at line 31: '
#line 31 "py_strip.lxx"
{ echo(); start(q); }
            break;
          case 3: // rule at line 32: '''
#line 32 "py_strip.lxx"
{ echo(); start(qqq); }
            break;
          case 4: // rule at line 33: "
#line 33 "py_strip.lxx"
{ echo(); start(Q); }
            break;
          case 5: // rule at line 34: """
#line 34 "py_strip.lxx"
{ echo(); start(QQQ); }

   /* How the quoted strings end */
            break;
          case 6: // rule at line 62: False|await|else|import|pass
#line 62 "py_strip.lxx"
echo();
            break;
          case 7: // rule at line 63: None|break|except|in|raise
#line 63 "py_strip.lxx"
echo();
            break;
          case 8: // rule at line 64: True|class|finally|is|return
#line 64 "py_strip.lxx"
echo();
            break;
          case 9: // rule at line 65: and|continue|for|lambda|try
#line 65 "py_strip.lxx"
echo();
            break;
          case 10: // rule at line 66: as|def|from|nonlocal|while
#line 66 "py_strip.lxx"
echo();
            break;
          case 11: // rule at line 67: assert|del|global|not|with
#line 67 "py_strip.lxx"
echo();
            break;
          case 12: // rule at line 68: async|elif|if|or|yield
#line 68 "py_strip.lxx"
echo();
    /* Built-in function names from
     * https://docs.python.org/3/library/functions.html
     */
            break;
          case 13: // rule at line 72: abs|delattr|hash|memoryview|set|all
#line 72 "py_strip.lxx"
echo();
            break;
          case 14: // rule at line 73: dict|help|min|setattr|any|dir|hex
#line 73 "py_strip.lxx"
echo();
            break;
          case 15: // rule at line 74: next|slice|ascii|divmod|id|object
#line 74 "py_strip.lxx"
echo();
            break;
          case 16: // rule at line 75: sorted|bin|enumerate|input|oct
#line 75 "py_strip.lxx"
echo();
            break;
          case 17: // rule at line 76: staticmethod|bool|eval|int|open|str
#line 76 "py_strip.lxx"
echo();
            break;
          case 18: // rule at line 77: breakpoint|exec|isinstance|ord|sum
#line 77 "py_strip.lxx"
echo();
            break;
          case 19: // rule at line 78: bytearray|filter|issubclass|pow
#line 78 "py_strip.lxx"
echo();
            break;
          case 20: // rule at line 79: super|bytes|float|iter|print|tuple
#line 79 "py_strip.lxx"
echo();
            break;
          case 21: // rule at line 80: callable|format|len|property|type
#line 80 "py_strip.lxx"
echo();
            break;
          case 22: // rule at line 81: chr|frozenset|list|range|vars
#line 81 "py_strip.lxx"
echo();
            break;
          case 23: // rule at line 82: classmethod|getattr|locals|repr
#line 82 "py_strip.lxx"
echo();
            break;
          case 24: // rule at line 83: zip|compile|globals|map|reversed
#line 83 "py_strip.lxx"
echo();
            break;
          case 25: // rule at line 84: __import__|complex|hasattr|max|round
#line 84 "py_strip.lxx"
echo();

  /* A handful of magic methods should also be preserved
   * (not an exhaustive list)
   */
            break;
          case 26: // rule at line 89: __new__|__init__|__del__
#line 89 "py_strip.lxx"
echo();
            break;
          case 27: // rule at line 90: __cmp__|__eq__|__ne__
#line 90 "py_strip.lxx"
echo();
            break;
          case 28: // rule at line 91: __lt__|__gt__|__le__|__ge__
#line 91 "py_strip.lxx"
echo();
            break;
          case 29: // rule at line 92: __pos__|__neg__|__abs__
#line 92 "py_strip.lxx"
echo();
            break;
          case 30: // rule at line 93: __add__|__sub__|__mul__|__div__
#line 93 "py_strip.lxx"
echo();
            break;
          case 31: // rule at line 94: __str__|__repr__|__format__
#line 94 "py_strip.lxx"
echo();
            break;
          case 32: // rule at line 95: __iter__|__len__|__contains__
#line 95 "py_strip.lxx"
echo();



   /* We reduce all other identifiers starting with a lower-case letter
    * to the representative token 'i', and all identifiers starting
    * with an upper-case letter to 'I', and identifiers starting with
    * '_' to '_'.
    */

            break;
          case 33: // rule at line 105: [a-z][0-9A-Z_a-z]*
#line 105 "py_strip.lxx"
{ std::cout << "i"; }
            break;
          case 34: // rule at line 106: [A-Z][0-9A-Z_a-z]*
#line 106 "py_strip.lxx"
{ std::cout << "I"; }
            break;
          case 35: // rule at line 107: [_][0-9A-Z_a-z]*
#line 107 "py_strip.lxx"
{ std::cout << "_"; }

  /* Whitespace is significant in Python, so we don't discard it all, but
   * we will chop it at the end of the line. Compress away blank lines.
   * Also remove lines containing only comments.
   */

            break;
          case 36: // rule at line 114: (?:[\x09\x0a\x0d\x20]|#.*)*\n
#line 114 "py_strip.lxx"
{ std::cout << "\n"; }

  /* Everything else is preserved. '.' matches any character but newline. */
            break;
          case 37: // rule at line 117: .
#line 117 "py_strip.lxx"
echo();

            break;
        }
        break;
      case q:
        matcher().pattern(PATTERN_q);
        switch (matcher().scan())
        {
          case 0:
            if (matcher().at_end())
            {
#line 119 "py_strip.lxx"
{ return 0; }

            }
            else
            {
              lexer_error("scanner jammed");
              return int();
            }
            break;
          case 1: // rule at line 37: '
#line 37 "py_strip.lxx"
{ std::cout << "@"; echo(); start(INITIAL); }
            break;
          case 2: // rule at line 44: [\x5c].
#line 44 "py_strip.lxx"
{ ;  }

  /* Only triple-quoted strings can gobble unescaped newlines.
   *  (Note the wild-card character '.' does not match newline)
   */
            break;
          case 3: // rule at line 54: .
#line 54 "py_strip.lxx"
{ ;  }


  /* Keywords and built-in functions that we preserve.
   * We want these to take precedence over the identifier pattern.
   * Keywords from
   * https://docs.python.org/3/reference/lexical_analysis.html#keywords
   */
            break;
        }
        break;
      case Q:
        matcher().pattern(PATTERN_Q);
        switch (matcher().scan())
        {
          case 0:
            if (matcher().at_end())
            {
#line 119 "py_strip.lxx"
{ return 0; }

            }
            else
            {
              lexer_error("scanner jammed");
              return int();
            }
            break;
          case 1: // rule at line 39: "
#line 39 "py_strip.lxx"
{ std::cout << "@"; echo(); start(INITIAL); }
            break;
          case 2: // rule at line 44: [\x5c].
#line 44 "py_strip.lxx"
{ ;  }

  /* Only triple-quoted strings can gobble unescaped newlines.
   *  (Note the wild-card character '.' does not match newline)
   */
            break;
          case 3: // rule at line 54: .
#line 54 "py_strip.lxx"
{ ;  }


  /* Keywords and built-in functions that we preserve.
   * We want these to take precedence over the identifier pattern.
   * Keywords from
   * https://docs.python.org/3/reference/lexical_analysis.html#keywords
   */
            break;
        }
        break;
      case qqq:
        matcher().pattern(PATTERN_qqq);
        switch (matcher().scan())
        {
          case 0:
            if (matcher().at_end())
            {
#line 119 "py_strip.lxx"
{ return 0; }

            }
            else
            {
              lexer_error("scanner jammed");
              return int();
            }
            break;
          case 1: // rule at line 38: '''
#line 38 "py_strip.lxx"
{ echo(); std::cout << "@"; start(INITIAL); }
            break;
          case 2: // rule at line 44: [\x5c].
#line 44 "py_strip.lxx"
{ ;  }

  /* Only triple-quoted strings can gobble unescaped newlines.
   *  (Note the wild-card character '.' does not match newline)
   */
            break;
          case 3: // rule at line 49: \n
#line 49 "py_strip.lxx"
{ ; }

  /* They gobble anything else. We do it one character at a time so that
   * we don't have to make exceptions for the quote marks.
   */
            break;
          case 4: // rule at line 54: .
#line 54 "py_strip.lxx"
{ ;  }


  /* Keywords and built-in functions that we preserve.
   * We want these to take precedence over the identifier pattern.
   * Keywords from
   * https://docs.python.org/3/reference/lexical_analysis.html#keywords
   */
            break;
        }
        break;
      case QQQ:
        matcher().pattern(PATTERN_QQQ);
        switch (matcher().scan())
        {
          case 0:
            if (matcher().at_end())
            {
#line 119 "py_strip.lxx"
{ return 0; }

            }
            else
            {
              lexer_error("scanner jammed");
              return int();
            }
            break;
          case 1: // rule at line 40: """
#line 40 "py_strip.lxx"
{ std::cout << "@"; echo(); start(INITIAL);}


   /* They all gobble any escaped character */
            break;
          case 2: // rule at line 44: [\x5c].
#line 44 "py_strip.lxx"
{ ;  }

  /* Only triple-quoted strings can gobble unescaped newlines.
   *  (Note the wild-card character '.' does not match newline)
   */
            break;
          case 3: // rule at line 49: \n
#line 49 "py_strip.lxx"
{ ; }

  /* They gobble anything else. We do it one character at a time so that
   * we don't have to make exceptions for the quote marks.
   */
            break;
          case 4: // rule at line 54: .
#line 54 "py_strip.lxx"
{ ;  }


  /* Keywords and built-in functions that we preserve.
   * We want these to take precedence over the identifier pattern.
   * Keywords from
   * https://docs.python.org/3/reference/lexical_analysis.html#keywords
   */
            break;
        }
        break;
      default:
        start(0);
    }
  }
}

////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  SECTION 3: user code                                                      //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////

#line 122 "py_strip.lxx"

/* For simple filters, the main program can go here. */

int main() {  yy::Lexer().yylex(); exit(0); }
